\documentclass[12pt, letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage[margin=1in, left=0.75in, right=0.75in]{geometry}
\usepackage{booktabs}
\usepackage{tabu}
\usepackage[labelfont=bf, skip=5pt, font=small]{caption}
\usepackage{subcaption}
\usepackage[style=chem-acs, articletitle=true]{biblatex}
\usepackage{tocloft}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{amsmath}
% \addbibresource{}

\setlength{\parskip}{2em}
\setlength{\parindent}{0em}

\begin{document}

\begin{center}
    % \vspace*{-1in}
    % \vspace*{0.5em}
    \Huge\textbf{Tracking Players In \\ Sports Videos} \\[12pt]
    \Large{An investigation into tracking ice hockey \\ players in professional matches} \\[55pt]
    \huge\textbf{Yerassyl Kutylbek} \\[6pt]
    \Large\textbf{ID Number:} {10825970} \\[5pt]
    \Large{Supervised by Dr Aphrodite Galata} \\[5pt]
    \date\Large{April 30, 2024} \\[90pt]

    \large{A report submitted as part of the Third Year Project for} \\[3pt]
    \large{the degree of BSc (Hons) Artificial Intelligence}
    \centering
    \includegraphics[width=0.6\textwidth]{images/uom_logo.png} \\
    \large{School of Computer Science} \\[5pt]
    \large{The University of Manchester}
\end{center}

\tableofcontents
\newpage

\hypertarget{listoftables}{}
\addcontentsline{toc}{section}{\protect\hyperlink{listoftables}{List of Tables}} 
\listoftables
\newpage

\hypertarget{listoffigures}{}
\addcontentsline{toc}{section}{\protect\hyperlink{listoffigures}{List of Figures}} 
\listoffigures
\newpage

% Abstract
\section*{\Huge Abstract}
\addcontentsline{toc}{section}{Abstract}
\begin{spacing}{1.3}
% Abstract text here
In the context of ice hockey, a sport known for its speed and complexity, the need for advanced player-tracking systems is particularly pronounced. This project introduces a comprehensive system designed to track ice hockey players in professional match videos with unprecedented accuracy and efficiency, leveraging the YOLO object detection framework and Deep SORT algorithm to accurately identify and follow players, and clustering techniques to distinguish teams and referees. It represents a significant leap in sports analytics, offering precise player detection and tracking, team classification, and a bird's-eye view transformation of the ice rink for advanced strategic analysis. Evaluated across key metrics, the system achieved an impressive player and referee detection mean Average Precision (mAP) of 96\% and facilitated groundbreaking insights into player positioning and team tactics through its bird's-eye view feature. This advancement underscores the transformative potential of integrating machine learning and computer vision in sports analytics, providing a powerful tool for performance analysis and showcasing a notable contribution to the strategic understanding of professional ice hockey.
\end{spacing}
\newpage

% Declaration
% \section*{\Huge Declaration}
% \addcontentsline{toc}{section}{Declaration}
% Declaration text here
% \newpage

% Acknowledgements
% \section*{\Huge Acknowledgements}
% \addcontentsline{toc}{section}{Acknowledgements}
% Acknowledgements text here
% \newpage

\section{Introduction}

{
\setlength{\parskip}{0.3cm}
\subsection{Context and Motivation}
\begin{spacing}{1.2}
The emergence of advanced analytics in sports, leveraging machine learning and computer vision, has revolutionized how games are analyzed and understood. Specifically, ice hockey, with its fast-paced and intricate team dynamics, presents a unique set of challenges and opportunities for technological innovation. This project lies at the intersection of these technological advancements and the growing demand for in-depth sports analytics.

The primary motivation for this investigation stems from the inherent limitations of traditional player tracking methods in ice hockey, which are mainly manual, tedious, and not sufficiently robust to capture the complex, high-speed movements that are typical of the sport. These traditional methods often yield data that lacks the depth and precision necessary for a comprehensive analysis of player performance and team strategies.

% In response to these challenges, recent studies have explored the potential of machine learning and computer vision to provide more detailed and accurate tracking of player movements. For instance, the work by [Author et al., Year] demonstrated the application of the YOLO (You Only Look Once) object detection model and Deep SORT tracking algorithm in real-time player tracking across various sports. However, the unique context of ice hockey, with its rapid changes in player positions and frequent occlusions, calls for a specialized approach that can reliably distinguish between players, referees, and the puck, while also adapting to the sport's fast-paced nature.

This project aims to develop a comprehensive system tailored to the specific demands of ice hockey, including advanced object detection, player tracking, and team classification methodologies. Consequently, the goal is to address the essential requirement for accurate and automated tracking in professional ice hockey games, offering teams and coaches valuable insights to guide strategic choices and improve overall team performance.

Furthermore, the project recognizes the growing interest in sports analytics for performance optimization and enhancing fan engagement and viewership experiences. By facilitating a more detailed analysis of game dynamics, player tracking systems contribute to more engaging and immersive viewing experiences, potentially transforming how fans engage with the sport.

In summary, this project is motivated by the intersection of technical challenges, the potential for significant contributions to sports analytics in ice hockey, and the broader implications for team performance and fan engagement. Through the investigation grounded in the latest research and technological innovations, it aims to push the boundaries of what is possible in sports analytics and player tracking.
\end{spacing}
}
\newpage

{
\setlength{\parskip}{0.3cm}
\subsection{Aims and Objectives}
The project aims to develop a comprehensive system for tracking ice hockey players and referees in professional match videos with high accuracy and efficiency. The objectives include:

1. Implementing an advanced object detection model to accurately identify players and referees.

2. Utilizing a robust tracking algorithm to maintain consistent player identities across video frames.

3. Differentiating between opposing teams using clustering techniques.

4. Mapping player positions from video frames to a 2D rink model for strategic analysis.

5. Generating heat maps to visualize player movements and game dynamics.

6. Evaluating the system's performance across various metrics, including detection accuracy, tracking consistency, and computational efficiency.
}

{
\setlength{\parskip}{0.3cm} % Adjust the vertical space between paragraphs as needed
\subsection{Report Structure}
The report is structured into six chapters to systematically cover every aspect of the project:

\begin{itemize}
    \item Chapter 1: Introduces the project, outlining the context, motivation, aims, and objectives.
    
    \item Chapter 2: Reviews relevant literature and technologies that underpin the methodologies applied in this project, providing a foundation for the approaches chosen.
    
    \item Chapter 3: Details the methodology and implementation process, including planning, data collection and annotation, detection and tracking of players and referees, team classification, bird’s-eye view transformation, and heatmap generation.
    
    \item Chapter 4: Focuses on the evaluation of the system, discussing the preparation of datasets, detection and tracking accuracy, parameter optimization, and overall system performance.
    
    \item Chapter 5: Discusses the project's achievements, reflecting on the challenges faced, insights gained, and potential areas for further research. Additionally, concludes the report, summarizing the key outcomes and proposing directions for future work on the topic.
\end{itemize}
}
\newpage

\section{Background}



{
\setlength{\parskip}{0.3cm}
\subsection{Relevant Work}
\begin{spacing}{1.2}
1. \textbf{Buric, M., Ivasic-Kos, M., \& Pobar, M. (2019).} "Player Tracking in Sports Videos."
% This study addresses the challenges of tracking players in handball videos, where players frequently occlude each other and exhibit rapid, unpredictable movements. The authors explore the application of CNN-based object detectors, particularly focusing on YOLO, and evaluate three tracking-by-detection methods: the Hungarian assignment algorithm, SORT (Simple Online and Real-time Tracking), and Deep SORT for their effectiveness in this challenging environment. 
This paper tackles the complex issue of tracking players in handball videos, where players frequently occlude each other and exhibit rapid, unpredictable movements. The authors explore the application of CNN-based object detectors, particularly focusing on YOLO, and evaluate three tracking-by-detection methods: the Hungarian assignment algorithm, SORT (Simple Online and Real-time Tracking), and Deep SORT for their effectiveness in this challenging environment. The evaluation on a custom dataset demonstrates the viability of these methods for sports player tracking 

\href{https://consensus.app/papers/player-tracking-sports-videos-buric/c3cd64da157a5e589e69d84d95373adb/?utm_source=chatgpt}{(Buric et al., 2019)}.

2. \textbf{Soomro, K., Khokhar, S., \& Shah, M. (2015).} "Tracking When the Camera Looks Away." 
% This innovative study addresses the challenge of tracking players across temporally disjoint sequences of soccer videos, such as those with intermittent advertisements or camera view changes. By employing a graph-based optimization approach without using appearance cues, and instead leveraging team formations, the authors offer a novel solution for continuous player tracking. 
This innovative study addresses the challenge of tracking players across temporally disjoint sequences of soccer videos, such as those with intermittent advertisements or camera view changes. By employing a graph-based optimization approach without using appearance cues, and instead leveraging team formations, the authors offer a novel solution for continuous player tracking. This method also facilitates tactical and statistical game analysis, presenting a significant advancement in sports video analysis technology

\href{https://consensus.app/papers/tracking-when-camera-looks-away-soomro/d33a6a9f5abc50c6b99bbaaadee74e16/?utm_source=chatgpt}{(Soomro et al., 2015)}.

3. \textbf{Manafifard, M., Ebadi, H., \& Moghaddam, H. (2017).} "A survey on player tracking in soccer videos." 
% This survey presents a comprehensive overview of soccer player tracking technologies, categorizing and examining the strengths and weaknesses of various preprocessing and processing methods. 
This survey presents a comprehensive overview of soccer player tracking technologies, categorizing and examining the strengths and weaknesses of various preprocessing and processing methods. The paper highlights the challenges posed by factors such as player occlusion and rapidly changing lighting conditions, offering insights into the state-of-the-art techniques and suggesting directions for future research in the domain of soccer video analysis

\href{https://consensus.app/papers/survey-player-tracking-soccer-videos-manafifard/880b411648dc551d9e811bc99470c446/?utm_source=chatgpt}{(Manafifard et al., 2017)}.

4. \textbf{Sudeep, K. M., Amarnath, V., Pamaar, A. R., De, K., Saini, R., \& Roy, P. P. (2018).} "Tracking Players in Broadcast Sports." 
% This research delves into the use of deep learning networks for identifying and tracking players in sports videos, introducing an algorithm that incorporates Kalman filters for enhanced tracking performance. 
This research delves into the use of deep learning networks for identifying and tracking players in sports videos, introducing an algorithm that incorporates Kalman filters for enhanced tracking performance. The study compares this new algorithm with traditional techniques like mean shift filters, showing promising results and paving the way for advanced sports analytics applications 

\href{https://consensus.app/papers/tracking-players-broadcast-sports-sudeep/4fb846770e345219850e425f227cd66f/?utm_source=chatgpt}{(Sudeep et al., 2018)}.

5. \textbf{Castro, R. L., Andrade, D., \& Fraguela, B. (2020).} "A Hybrid Approach for Tracking Individual Players in Broadcast Match Videos." 
% This paper presents a fast and accurate player tracking solution for broadcasted sports events, integrating multiple models that operate concurrently. 
This paper presents a fast and accurate player tracking solution for broadcasted sports events, integrating multiple models that operate concurrently. The solution is tested against manually labeled video sequences, demonstrating its capability to track players in real-time with high precision. This method stands out for its performance, processing high-definition videos at significant frame rates, a critical advancement for real-time sports analytics

\href{https://consensus.app/papers/hybrid-approach-tracking-individual-players-broadcast-castro/16e287d81de75e84a0372988c3772674/?utm_source=chatgpt}{(Castro et al., 2020)}.

6. \textbf{Jiang, X., Liu, Z., \& Wang, Y. (2016).} "Tracking Multiple Players in Beach Volleyball Videos." 
% Focusing on beach volleyball, this paper adopts the tracking-by-detection framework using the Multiple Hypotheses Tracking (MHT) algorithm. 
Focusing on beach volleyball, a sport with particularly complex player movements, this paper adopts the tracking-by-detection framework using the Multiple Hypotheses Tracking (MHT) algorithm. By incorporating motion information from the Kalman filter and training an online appearance model, the authors improve tracking efficiency, demonstrating the method's effectiveness with significant performance on custom datasets

\href{https://consensus.app/papers/tracking-multiple-players-beach-volleyball-videos-jiang/c3d1612f3ef75e5e8a6f444a0e67e092/?utm_source=chatgpt}{(Jiang et al., 2016)}.

7. \textbf{Martins, E., \& Brito, J. H. (2021).} "Soccer Player Tracking in Low Quality Video." 
% A system is proposed for tracking multiple soccer players in low-quality video streams, demonstrating the system's robustness and high performance. 
This study introduces a system capable of effectively tracking multiple soccer players in low-quality video streams. By adapting a state-of-the-art Multiple Object Tracking framework and creating detection and tracking datasets for various video qualities, the authors showcase the system's robustness and high performance, addressing a significant gap in sports video analysis for low-resolution footage

\href{https://consensus.app/papers/soccer-player-tracking-quality-video-martins/52e9b286c14e5787acfbd18fc50042c4/?utm_source=chatgpt}{(Martins \& Brito, 2021)}.

8. \textbf{Bastanfard, A., Jafari, S., \& Amirkhani, D. (2019).} "Improving Tracking Soccer Players in Shaded Playfield Video." 
% Addressing the challenge of tracking players in shaded playfields, this paper proposes an algorithm for player identification and tracking. 
This paper proposes an algorithm for tracking soccer players in videos with challenging lighting conditions, such as shaded playfields. By employing saliency maps for playfield identification and combining color, brightness, and edge features for player detection, the authors achieve high accuracy in player tracking. This approach significantly reduces the impact of lighting variations on tracking performance, offering valuable insights for analyzing outdoor sports videos

\href{https://consensus.app/papers/improving-tracking-soccer-players-shaded-playfield-video-bastanfard/e5e9097c3d335d8da4803d4ec8711727/?utm_source=chatgpt}{(Bastanfard et al., 2019)}.

9. \textbf{Ibraheem, O., Irwansyah, A., Hagemeyer, J., Porrmann, M., \& Rückert, U. (2017).} "Reconfigurable vision processing system for player tracking in indoor sports." 
% The authors present a reconfigurable system that uses FPGA technology to accelerate the player tracking process in indoor sports. 
The authors present a reconfigurable system that uses FPGA technology to accelerate the player tracking process in indoor sports, processing live and recorded video data from multiple cameras. The system's player detection and tracking capabilities achieve high accuracy and efficiency, demonstrating a significant advancement in real-time sports analytics

\href{https://consensus.app/papers/vision-processing-system-player-tracking-sports-ibraheem/752c4500b471561bb821a1ec1debfac2/?utm_source=chatgpt}{(Ibraheem et al., 2017)}.

10. \textbf{Sverrisson, S., Grancharov, V., \& Pobloth, H. (2019).} "Real-Time Tracking-by-Detection in Broadcast Sports Videos." 
% This research introduces a novel real-time tracking-by-detection algorithm tailored for sports videos. 
This research introduces a novel real-time tracking-by-detection algorithm tailored for sports videos, combining an optimized Convolutional Neural Network architecture with a unique Inter Frame Connection logic. This approach enhances data association and stabilizes detection performance, outperforming existing tracking models and offering significant improvements for real-time player tracking applications 

\href{https://consensus.app/papers/realtime-trackingbydetection-broadcast-sports-videos-sverrisson/e07927d4fb4e5c338adf4b97696c541a/?utm_source=chatgpt}{(Sverrisson et al., 2019)}.


\end{spacing}
}




{
\setlength{\parskip}{0.3cm}
\subsection{Machine Learning in Sports Analytics}
\begin{spacing}{1.2}
The integration of machine learning (ML) into sports analytics marks a paradigm shift from conventional statistical methods to more sophisticated, predictive models that can analyze complex patterns and interactions within sports data. This transition is driven by the demand for more accurate analytics to enhance team performance, strategy formulation, and player evaluation. Machine learning (ML) is a branch of artificial intelligence that focuses on building systems that learn from data. Rather than being explicitly programmed to perform a task, these systems are trained on a dataset, allowing them to improve their performance over time as they are exposed to more data. In the context of sports analytics, ML techniques are used to process and analyze vast amounts of game data to uncover patterns, make predictions, and provide insights that can enhance decision-making for teams and coaches.

The effectiveness of machine learning in sports analytics is predicated on its ability to handle the high dimensionality of sports data and to learn from data to make accurate predictions or classifications. Unlike traditional statistical methods that often require simplifications or assumptions about the data, ML algorithms can model complex relationships within the data, offering a more nuanced understanding of game dynamics. This capability is valuable in sports like ice hockey, where the fast pace and intricate team dynamics present unique analytical challenges.

The integration of machine learning into sports analytics represents a significant advancement in how sports data is analyzed and utilized. By leveraging complex algorithms to interpret and predict sports outcomes, ML opens new avenues for performance optimization, strategic planning, and enhancing the competitive edge of teams and athletes. This overview sets the stage for exploring specific ML techniques and their application in tracking players in professional ice hockey matches, which is the focus of this project.

% References:
% Rein, R., & Memmert, D. (2016). Big data and tactical analysis in elite soccer: Future challenges and opportunities for sports science. SpringerPlus, 5(1), 1410.
% Gudmundsson, J., & Horton, M. (2017). Spatio-temporal analysis of team sports. ACM Computing Surveys (CSUR), 50(2), Article 22.

\subsubsection{Convolutional Neural Networks (CNNs) in Player Detection}
One of the key ML techniques employed in player detection within sports videos is the convolutional neural network (CNN). CNNs are a class of deep neural networks that are particularly effective at analyzing visual imagery. They use a series of convolutional layers to automatically and adaptively learn spatial hierarchies of features from input images. This capability makes them exceptionally suited for tasks such as image recognition, object detection, and even video analysis.

Convolutional Neural Networks (CNNs) stand out in the machine learning landscape for their exceptional ability to process and analyze images, making them ideal for applications such as player detection in sports videos. The architecture of a CNN is designed to mimic the way the human visual cortex works, allowing it to efficiently recognize patterns, shapes, and objects within complex visual inputs.

A CNN is composed of several layers that process and transform the input image to extract relevant features for the task at hand, such as detecting players on a sports field. A CNN architecture is shown in Figure~\ref{fig:cnn}. These layers include:

\begin{itemize}
    \item \textbf{Convolutional Layers}: The backbone of a CNN, these layers apply filters (or kernels) to the input image to create feature maps. Each filter is designed to detect specific features, such as edges, textures, or parts of objects (e.g., a player's jersey or helmet). By sliding the filter across the image, the network can capture spatial hierarchies of features, from simple to complex.

    \item \textbf{Activation Layers}: Following convolution, an activation function such as the Rectified Linear Unit (ReLU) is applied to introduce non-linearity into the network. This step is crucial for enabling the CNN to learn and model complex patterns in the data.

    \item \textbf{Pooling Layers}: These layers reduce the dimensionality of the feature maps, making the detection process computationally efficient while retaining essential information. Max pooling, for example, reduces the size of the feature maps by taking the maximum value in a specific window, enhancing the network's ability to focus on the most prominent features.

    \item \textbf{Fully Connected Layers}: Towards the end of the CNN architecture, fully connected layers combine all the features learned by previous layers to classify the image or detect objects within it. In the context of player detection, this involves determining whether a region of the image contains a player and identifying the player's location.

    \item \textbf{Output Layer}: The final layer outputs the detection results, typically in the form of bounding boxes around detected players and classification scores indicating the confidence level of the detections.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{images/CNN.png}
\captionsetup{font=large}
\caption{Convolutional Neural Network}
\label{fig:cnn}
\end{figure}

Training a CNN involves showing it thousands of labeled images, where the locations of players are marked with bounding boxes. The network adjusts its weights through a process known as backpropagation, where the difference between the predicted output and the actual label is used to update the weights in a way that minimizes this difference. This learning process enables the CNN to improve its ability to detect players as it goes through more training images.

The YOLO algorithm represents a significant advancement in utilizing CNNs for object detection, including player detection. Unlike traditional approaches that scan an image in parts to find objects, YOLO looks at the entire image in a single pass, predicting bounding boxes and class probabilities directly from the full images. This holistic approach allows YOLO to detect objects, such as players, rapidly and accurately, making it highly effective for real-time sports analytics applications.

By leveraging CNNs and advanced algorithms like YOLO, player detection systems can achieve remarkable accuracy, enabling detailed analysis of game dynamics and player movements without manual labeling or tracking. This automated, efficient processing of visual data opens up new possibilities for enhancing sports strategies, player evaluations, and audience engagement through enriched visual content.

\subsubsection{Support Vector Machines (SVMs) for Player Classification}

Support Vector Machines (SVMs) serve as a robust tool for classification tasks within the domain of machine learning, excelling for tasks such as differentiating between player types or identifying referees among players in the context of sports analytics. SVM is a supervised learning model renowned for its application in both classification and regression challenges.

The fundamental operation of an SVM Figure~\ref{fig:SVM} involves constructing a hyperplane in a high-dimensional space. The goal is to find the hyperplane that best divides the dataset into classes, which is particularly advantageous for binary classification tasks. The decision to designate a hyperplane as "the best" hinges on its ability to offer the largest margin between the two classes it separates. This margin is the distance between the hyperplane and the nearest data point from either class, known as a support vector.

The steps to achieve this are as follows:

\begin{itemize}
    \item \textbf{Transformation into High-Dimensional Space}: In scenarios where the data is not linearly separable in its original space, SVM employs a technique called the kernel trick. This approach transforms the input data space into a higher-dimensional space where a linear separation is feasible without explicitly computing the coordinates in this new space, thus preserving computational efficiency.

    \item \textbf{Optimization of the Hyperplane}: The SVM algorithm seeks to maximize the margin between the classes by adjusting the orientation and position of the hyperplane. This process involves solving an optimization problem that determines the hyperplane parameters minimizing classification errors while maximizing the margin.

    \item \textbf{Support Vectors Identification}: The data points that are closest to the hyperplane and directly influence its position and orientation are identified as support vectors. These points are critical since their removal or alteration would change the hyperplane's construction.

    \item \textbf{Classification Decision}: Once the optimal hyperplane is established, SVM can classify new data points based on which side of the hyperplane they fall on. For binary classification, this involves assigning a class label based on the sign of the decision function, which is a measure of the distance of a data point from the hyperplane.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\linewidth]{images/SVM.png}
\captionsetup{font=large}
\caption{Support Vector Machine}
\label{fig:SVM}
\end{figure}

In the realm of sports analytics, particularly in the context of tracking players in videos, SVMs play a crucial role in classifying detected objects post their detection. Features such as HSV histograms, extracted from the bounding boxes around detected players serve as inputs to the SVM. Based on these features, the SVM classifies each object as either a player, a referee, or an irrelevant object. This classification step is instrumental in refining the detection accuracy by filtering out objects that do not pertain to the game's context.

In essence, SVMs complement the object detection capabilities of CNNs by providing a reliable method for the subsequent classification of detected objects. This synergy between CNNs and SVMs empowers the development of sophisticated player tracking systems, driving forward the analytics in sports through detailed game dynamics and player performance insights.

\end{spacing}
}

{
\setlength{\parskip}{0.3cm}
\subsection{Player Detection}
\begin{spacing}{1.2}

In the evolving landscape of sports analytics, especially in player detection within sports videos, the You Only Look Once (YOLO) algorithm has emerged as a game-changer. YOLO is an object detection system that differs fundamentally from the detection systems that came before it. Unlike systems that apply the detection model to various regions of the image, YOLO frames object detection as a single regression problem, directly from image pixels to bounding box coordinates and class probabilities. This approach allows YOLO to achieve remarkable speed and accuracy, making it ideal for player detection in sports analytics.

\subsubsection{Understanding YOLO's Mechanism}
YOLO divides the input image into a grid (e.g., 13x13). For each grid cell, it predicts multiple bounding boxes and confidence scores for those boxes. The confidence score reflects the accuracy of the bounding box and the probability that the box contains a specific object. Alongside, YOLO predicts class probabilities for each bounding box. The combination of the bounding box confidence score and the class prediction determines the final probability that a box contains a specific type of object, such as a player.

\subsubsection{Grid Division and Bounding Box Prediction}

The YOLO framework begins by dividing the input image into an $S \times S$ grid. Each grid cell predicts bounding boxes and their associated properties as shown in Figure~\ref{fig:GridPred}:

\begin{itemize}
    \item The center of the bounding box $(b_x, b_y)$, relative to the bounds of the grid cell.
    \item The width $(b_w)$ and height $(b_h)$ of the bounding box, relative to the entire image.
    \item A confidence score that signifies the box's accuracy and the likelihood that it contains an object.
\end{itemize}

The formulas for the bounding box predictions are as follows:
\begin{align*}
    b_x &= \sigma(t_x) + c_x \\
    b_y &= \sigma(t_y) + c_y \\
    b_w &= p_w e^{t_w} \\
    b_h &= p_h e^{t_h} \\
    \text{Confidence} &= \sigma(t_o)
\end{align*}

where:
\begin{itemize}
    \item $\sigma$ represents the sigmoid function, ensuring outputs between 0 and 1.
    \item $t_x, t_y, t_w, t_h$ are the model's predictions
    \item $c_x, c_y$ represent the top-left corner of the grid cell
    \item $p_w$ and $p_h$ are predefined dimensions of the bounding boxes.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\linewidth]{images/GridPred.png}
\captionsetup{font=large}
\caption{Grid Division and Bounding Box Prediction}
\label{fig:GridPred}
\end{figure}


\subsubsection{Class Probability Prediction}

For each grid cell, YOLO predicts conditional class probabilities $Pr(Class_i | Object)$ for $C$ classes, using the formula:
\begin{equation*}
    Pr(Class_i | Object) = \sigma(t_{i})
\end{equation*}
where $t_{i}$ is the predicted probability for class $i$.

This prediction is independent of the bounding boxes, assuming every box has the same class distribution.


\subsubsection{Non-max Suppression}
After predicting bounding boxes and class probabilities, non-max suppression (NMS) is applied to reduce overlapping boxes, keeping only the box with the highest confidence score while removing others that predict the same object. This step is crucial for reducing the number of false positives as shown in Figure~\ref{fig:NMS}. NMS steps:
\begin{enumerate}
    \item Sort all bounding boxes by their confidence scores in descending order.
    \item Keep the highest confidence box and remove others with an IOU greater than a certain threshold.
    \item Repeat step 2 for the remaining boxes.
\end{enumerate}

The Intersection Over Union (IOU) metric plays a central role in this process by quantifying the overlap between bounding boxes, enabling the algorithm to determine which boxes to keep and which to discard. IOU is a measure used to evaluate the similarity between two bounding boxes. It is defined as the ratio of the area of overlap between the two bounding boxes to the area of their union. Mathematically, it can be expressed as:
\begin{equation*}
    IOU = \frac{Area\: of\: Overlap}{Area\: of\: Union}
\end{equation*}

The value of IOU ranges from 0 to 1, where 0 indicates no overlap and 1 represents perfect overlap. In the context of non-max suppression, IOU is used to compare each pair of bounding boxes that detect the same object.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\linewidth]{images/NMS.png}
\captionsetup{font=large}
\caption{Non-max Suppression}
\label{fig:NMS}
\end{figure}


\subsubsection{Combining Predictions}
Finally, YOLO combines the bounding box predictions with the class probability predictions:
\begin{equation*}
    Score_{class_i} = Pr(Object) \times IOU_{pred}^{truth} \times Pr(Class_i | Object)
\end{equation*}

This approach enables YOLO to efficiently detect objects, including player detection in sports analytics.

\end{spacing}
}


{
\setlength{\parskip}{0.3cm}
\subsection{Color-based Team Classification using HSV Histograms and K-means Clustering}
\begin{spacing}{1.2}

The identification of players in sports analytics, particularly in dynamic and fast-paced environments like ice hockey, is crucial for player tracking, performance analysis, and tactical assessment. Distinguishing between two teams and referees through their jerseys is a common approach. This section explores the technical details leveraging the HSV color space and K-means clustering to achieve robust team classification against the challenges posed by variable lighting and diverse camera angles.

\subsubsection{HSV Histograms for Color Feature Extraction}

HSV color space offers a more intuitive arrangement of colors as shown in Figure~\ref{fig:HSV}, making it easier to handle variations in lighting when processing video frames. HSV separates the color (hue) from the brightness (value), which is particularly useful in sports analytics where lighting can significantly vary. It consists of:
\begin{itemize}
    \item \textbf{Hue (H):} The color type, represented as an angle from 0 to 360 degrees. Normalized to 0 to 1 (or 0 to 255).
    \item \textbf{Saturation (S):} The intensity of the color, from pure (100\%) to grayscale (0\%).
    \item \textbf{Value (V):} The brightness of the color, where 0 is black, and 100\% shows the most color.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\linewidth]{images/HSV.jpeg}
\captionsetup{font=large}
\caption{HSV colour space}
\label{fig:HSV}
\end{figure}

A histogram for each HSV channel is computed for the player's jersey within a bounding box. The histograms are normalized to ensure consistency across different sizes of Region of Interest (ROI). The histograms are normalized as:
\[ H(i) = \frac{n_i}{N} \]
where \(n_i\) is the number of pixels in the $i^{th}$ bin, and \(N\) is the total number of pixels. 

This normalization process results in a feature vector for each channel, which, when concatenated, forms a comprehensive color feature vector for the ROI.

\subsubsection{Gaussian Blur}

Gaussian blur is utilized to preprocess the jersey's Region of Interest (ROI) by reducing noise, enabling a more accurate color histogram computation as shown in Figure~\ref{fig:GausianBlur}. The Gaussian function applied to each pixel \textit{x} in the image is given by:
\[ G(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}} \]
where \(\sigma\) is the standard deviation of the Gaussian distribution. 

This function smoothens color transitions and minimizes outliers as shown in Figure~\ref{fig:GausianBlur}, which might skew the histogram representation.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\linewidth]{images/GausianBlur.png}
\captionsetup{font=large}
\caption{Gausian Blur Effect}
\label{fig:GausianBlur}
\end{figure}

\subsubsection{Jersey ROI}
% A central portion, typically 50\% of the bounding box, is considered to ensure the histogram captures the dominant jersey color.

The Region of Interest (ROI) for each player's jersey is defined by zooming into the central part of the bounding box detected around a player as represented in Figure~\ref{fig:JerseyROI}. This is based on the most distinct and consistent color of a player’s team is on the jersey. To ensure the histogram focuses on this part, a fixed percentage (e.g., 50\%) reduction from the original bounding box dimensions centers the ROI on the jersey.

\subsubsection{Feature Vectors from HSV Histograms}

The feature vector for the jersey's color distribution is constructed by concatenating the normalized histograms of the H, S, and V channels. Given bins \textit{b} for each histogram, the feature vector \textit{F} can be represented as:
\[ F = [H_1, H_2, ..., H_b, S_1, S_2, ..., S_b, V_1, V_2, ..., V_b] \]
This vector is crucial, serving as the input for the subsequent K-means clustering for team classification.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.25\linewidth]{images/JerseyROI.jpeg}
\captionsetup{font=large}
\caption{Jersey Region of Interest}
\label{fig:JerseyROI}
\end{figure}

\subsubsection{K-means Clustering for Team Classification}

K-means clustering aims to partition \textit{n} observations into \textit{k} clusters in which each observation belongs to the cluster with the nearest mean as represented in Figure~\ref{fig:KmeansCluster}. K-means clustering partitions players into teams based on the similarity of their jersey colors. The clustering process works as follows:

\begin{enumerate}
    \item Initialization - select \(k\) cluster centroids randomly from the dataset, denoted as \(\mu_1, \mu_2, ..., \mu_k\) where \(k\) is the predefined number of clusters.
    \item Assignment Step - assign each data point \(x_i\) to the nearest cluster by calculating the Euclidean distance to each centroid and selecting the smallest. The assignment \(C(i)\) for each point \(x_i\) is given by:
    \[ C(i) = \arg\min_{k} \|\|x_i - \mu_k\|\|_2^2 \]
    \item Update Step - after all points have been assigned to clusters, update the centroids of the clusters to be the mean of the points assigned to each cluster. The updated position of centroid \(k\) is calculated as:
    \[ \mu_k = \frac{1}{|C_k|} \sum_{i \in C_k} x_i \]
    where \(C_k\) is the set of points assigned to cluster \(k\).
    \item Iteration - repeat the assignment and update steps iteratively until the centroids no longer change significantly, or a predefined number of iterations is reached. This implies convergence to a solution.
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\linewidth]{images/KmeansCluster.png}
\captionsetup{font=large}
\caption{K-means Clustering}
\label{fig:KmeansCluster}
\end{figure}


The objective is to minimize the within-cluster sum of squares (WCSS):
\[ \text{Minimize} \sum_{i=1}^{k}\sum_{x \in C_i} ||x - \mu_i||^2 \]
where \(C_i\) is the $i^{th}$ cluster, \(x\) is a feature vector, and \(\mu_i\) is the centroid of \(C_i\). 

% Through iterative updates, the algorithm converges, classifying players into two distinct clusters representing the teams.

The algorithm iterates between assigning observations to the nearest cluster centroid and updating the centroids based on the current cluster memberships until convergence.

In the context of team classification, this method effectively groups players into clusters (teams) based on their jersey colors represented by the feature vectors. This automatic categorization facilitates further analysis such as tracking, performance metrics, and tactical assessments in sports video analytics.


\end{spacing}
}


{
\setlength{\parskip}{0.3cm}
\subsection{Application of DeepSORT for Player Tracking}
\begin{spacing}{1.2}

DeepSORT (Simple Online and Realtime Tracking with a Deep Association Metric) builds upon the SORT (Simple Online and Realtime Tracking) algorithm, enhancing it with deep learning techniques to improve tracking accuracy, especially in challenging scenarios like occlusions and rapid movements. The technical core of DeepSORT includes feature extraction using deep learning, the Kalman filter for motion prediction, and the Hungarian algorithm for solving the assignment problem.


\subsubsection{Feature Extraction Using Deep Learning}

DeepSORT employs a convolutional neural network (CNN) to generate high-dimensional feature vectors for each detected player. These vectors are crucial for distinguishing players, especially when paths cross or occlude.

\textbf{CNN Architecture:} Pre-trained models such as ResNet or Inception are used to extract a high-dimensional feature vector from each detected bounding box in the video frame.

\textbf{Feature Vector:} A 128-dimensional feature vector is extracted for each player, capturing unique appearance aspects, aiding in their identification across frames.


\subsubsection{Motion Prediction with Kalman Filter}

The Kalman filter is used to predict player positions in subsequent frames based on their current state. It helps in maintaining tracking continuity even when detections may be temporarily lost or occluded.

\textbf{State Space:} Represented as \([x, y, \dot{x}, \dot{y}, s, \dot{s}]\), where \(x, y\) are position coordinates, \(\dot{x}, \dot{y}\) are velocities, \(s\) is the scale of the detection box, and \(\dot{s}\) is the scale change.

\textbf{Prediction and Update Equations:}

\begin{itemize}
    \item Prediction step estimates the next state based on current state and its estimated motion.
    \begin{align}
        \text{\textbf{State prediction}}: \hat{x}_{k|k-1} &= F_k \hat{x}_{k-1|k-1} + B_k u_k \\
        \text{\textbf{Covariance prediction}}: P_{k|k-1} &= F_k P_{k-1|k-1} F_k^T + Q_k
    \end{align}

    Where \(x\) is the state vector, \(P\) the state covariance, \(F\) the state transition model, \(B\) the control-input model, \(u\) the control vector, \(Q\) the process noise covariance.
    
    \item Update step then adjusts the prediction based on the new measurement (detection).
    \begin{align}
        \text{\textbf{Kalman gain}}: K_k &= P_{k|k-1} H_k^T (H_k P_{k|k-1} H_k^T + R_k)^{-1} \\
        \text{\textbf{State update}}: \hat{x}_{k|k} &= \hat{x}_{k|k-1} + K_k(z_k - H_k \hat{x}_{k|k-1}) \\
        \text{\textbf{Covariance update}}: P_{k|k} &= (I - K_k H_k) P_{k|k-1}
    \end{align}
    
    Where \(K\) the Kalman gain, \(H\) the observation model, and \(z\) the observation.
\end{itemize}


\subsubsection{Data Association with Hungarian Algorithm}

% The Hungarian algorithm matches predicted positions with new detections, considering both spatial and appearance similarities.

To match the predicted positions with new detections, DeepSORT uses the Hungarian algorithm, with the goal of minimizing the total cost, which incorporates both motion and appearance information. Hungarian algorithm is a combinatorial optimization algorithm that solves the assignment problem in polynomial time.

\textbf{Cost Matrix:} Constructed based on the Mahalanobis distance between predicted and detected positions, incorporating the appearance features' cosine similarity to penalize mismatches in appearance. The cost matrix \(C\) is defined such that each element \(C_{ij}\) represents the cost of assigning the \(i^{th}\) prediction to the \(j^{th}\) detection. This cost is computed by combining the Mahalanobis distance and the cosine distance between appearance features, as follows:

\[
C_{ij} = \alpha \cdot D_{\text{Mahal}}(i, j) + (1 - \alpha) \cdot D_{\text{cos}}(f_i, f_j)
\]

where:
\begin{itemize}
    \item \(D_{\text{Mahal}}(i, j)\) is the Mahalanobis distance between the predicted state of track \(i\) and the detected state of object \(j\).
    \item \(D_{\text{cos}}(f_i, f_j)\) is the cosine distance between the appearance feature vector \(f_i\) of track \(i\) and the feature vector \(f_j\) of detection \(j\).
    \item \(\alpha\) is a weighting factor that balances the contribution of the motion and appearance measures.
\end{itemize}

% \textbf{Optimization:} The Hungarian algorithm is applied to the cost matrix to find the assignment that minimizes the total cost, ensuring each prediction matches exactly one detection, considering both spatial and appearance similarities. This results in an optimal matching between existing tracks and new detections.

\textbf{Optimization:} The optimization of the cost matrix \(C\) to find the optimal assignment of predictions to detections is performed using the Hungarian algorithm. The goal is to minimize the total assignment cost. The optimization problem can be formalized as follows:

\[
\min \sum_{i=1}^{N} \sum_{j=1}^{M} C_{ij} x_{ij}
\]

subject to:
\begin{align*}
    \sum_{i=1}^{N} x_{ij} &= 1, \quad \forall j \in \{1, \ldots, M\}, \\
    \sum_{j=1}^{M} x_{ij} &= 1, \quad \forall i \in \{1, \ldots, N\}, \\
    x_{ij} &\in \{0, 1\},
\end{align*}

where:
\begin{itemize}
    \item \(N\) is the number of tracks (predictions).
    \item \(M\) is the number of detections.
    \item \(C_{ij}\) is the cost of assigning track \(i\) to detection \(j\).
    \item \(x_{ij}\) is a binary variable indicating whether track \(i\) is assigned to detection \(j\) (\(1\) for assigned, \(0\) otherwise).
\end{itemize}

The Hungarian algorithm efficiently finds the assignment \(x_{ij}\) that minimizes the total cost.


\subsubsection{Handling Occlusions and Identity Switches}

DeepSORT's use of appearance features with motion information significantly improves robustness to occlusions and identity switches.

\textbf{Occlusions:} The tracker relies more on the motion prediction when appearance information is unreliable due to occlusion. The stored appearance features of tracks help in re-identifying players once they are no longer occluded.

\textbf{Identity Switches:} By comparing the appearance features of current detections to those of existing (historical) tracks, DeepSORT reduces the risk of identity switches, especially in scenes with close interactions among players.


\subsubsection{Implementation Details}

\begin{itemize}
    \item \textbf{Frame-by-Frame Processing}: DeepSORT processes video frames in real-time, applying detection, feature extraction, and tracking sequentially on each frame.
    \item \textbf{Thresholds and Parameters}: Parameters such as the detection confidence threshold, the maximum age of a tracker, and the minimum number of frames for a track to be confirmed are critical for tuning performance and accuracy.
\end{itemize}


\end{spacing}
}



{
\setlength{\parskip}{0.3cm}
\subsection{Field Point Detection and Homography for 2D Rink Mapping}
\begin{spacing}{1.2}
This section delves into the integration of Field Point Detection with YOLO for identifying points on the ice rink, followed by an exploration of generating the homography matrix and mapping these detections onto a 2D representation of the rink.


\subsubsection{Integration of Field Point Detection with YOLO}
YOLO is a cutting-edge object detection system that predicts bounding boxes and probabilities for each image grid cell. When trained on specific rink features alongside players, YOLO can effectively detect and distinguish between dynamic play elements and static field points.

\paragraph{Training YOLO on Rink Features:}
To adapt YOLO for field point detection in ice hockey, the model is trained on a dataset comprising images of the rink annotated with both player positions and specific rink features such as \textbf{CHANGE} goal lines, blue lines, and face-off dots. This training enables YOLO to recognize and distinguish between dynamic elements (players) and static field points.

% Integrating field point detection with YOLO enables the simultaneous identification of players and critical rink markers. This dual detection capability is essential for accurately mapping player positions relative to key rink locations.

% \paragraph{Detection and Distinguishability:}
% Upon training, YOLO can simultaneously identify players and key rink features within video frames. This dual capability facilitates the accurate localization of players in relation to these static points, which is crucial for subsequent mapping and analysis.

\paragraph{Spatial Analysis Enhancement:}
Mapping player positions onto a 2D rink diagram using the homography matrix enables detailed spatial analysis. This process transforms detected positions from the video frame to the rink plane, facilitating strategy development and performance analysis. Utilizing the identified field points and player positions, spatial analyses such as player distribution, movement patterns, and team formations are significantly enhanced. These analyses are pivotal for developing game strategies and performance evaluation.


\subsubsection{Homography for 2D Rink Mapping}
Homography is a projective transformation that maps the points from one plane (the image plane) to another plane (the rink plane) using a \(3 \times 3\) matrix \(H\). This transformation is essential for converting the perspective view of a rink into a standardized 2D top-down view.

\paragraph{Mathematical Representation of Homography:}
The transformation of a point \((x, y)\) in the image plane to a point \((x', y')\) in the rink plane is governed by the equation:
\begin{equation}
    s \begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} = H \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}
\end{equation}
where \(s\) is a scalar ensuring the mapping is in homogeneous coordinates, allowing for translation, rotation, scaling, and perspective transformations.


\paragraph{Calculation of the Homography Matrix \(H\):}
The homography matrix \(H\) is computed using pairs of corresponding points from the image plane and the rink plane. A minimum of four point pairs is required to solve for \(H\), due to its eight degrees of freedom (the ninth parameter is the scale factor \(s\)). The Direct Linear Transformation (DLT) method and augmented by RANSAC for outlier rejection are typically employed to estimate \(H\) robustly.

% The homography matrix \(H\) is calculated using pairs of corresponding points. 


\subsubsection{Direct Linear Transformation (DLT):}
DLT is a straightforward algorithm for estimating \(H\) given a set of point pairs. It involves setting up a linear system based on the correspondences and solving for the homography matrix. The process can be outlined as follows:
\begin{enumerate}
    \item For each pair of corresponding points, create two equations that express the homographic relationship.
    \item Assemble these equations into a matrix form \(Ah = 0\), where \(A\) is a matrix constructed from the point coordinates, and \(h\) is the vectorized form of \(H\).
    \item Solve for \(h\) using singular value decomposition (SVD) to minimize \(||Ah||\) under the constraint \(||h||=1\).
\end{enumerate}

For a robust solution, SVD is employed on the matrix \(A\) formulated from these point correspondences. The SVD of \(A\) can be expressed as:

\begin{equation}
    A = U \Sigma V^T
\end{equation}

where \(U\) and \(V\) are orthogonal matrices, and \(\Sigma\) is a diagonal matrix containing the singular values of \(A\). The solution for \(h\), which is the vectorized form of \(H\), corresponds to the column of \(V\) associated with the smallest singular value in \(\Sigma\). This column effectively minimizes the equation \(Ah = 0\) under the constraint \(||h|| = 1\), leading to the estimation of \(H\).


\subsubsection{Robust Estimation with RANSAC:}
% Given the susceptibility of DLT to outliers (incorrect point correspondences), RANSAC is employed to robustly estimate \(H\). RANSAC iteratively selects a random subset of point pairs, estimates \(H\) using DLT, and then evaluates the quality of \(H\) by counting the number of inliers that fit the model well within a predefined error threshold. The \(H\) with the highest number of inliers is chosen as the final homography matrix.

The RANSAC algorithm enhances the robustness of homography estimation by iteratively selecting subsets of point pairs to compute \(H\), thereby mitigating the effect of outliers. The steps involved in RANSAC include:

\begin{enumerate}
    \item Randomly select a minimum set of point pairs necessary to compute \(H\).
    \item Estimate \(H\) using the selected points and DLT.
    \item Determine the inliers that fit well with the estimated \(H\) based on a predefined distance threshold.
    \item Repeat steps 1 to 3 for a predetermined number of iterations, selecting the \(H\) with the maximum number of inliers.
\end{enumerate}

This iterative process ensures the selection of the most reliable point pairs, significantly reducing the influence of incorrect correspondences and leading to a more accurate estimation of the homography matrix.

By applying DLT augmented with SVD for precision and employing RANSAC for outlier resistance, we achieve a highly reliable computation of \(H\), enabling accurate mapping of objects from the video frame to the 2D rink model. This methodology forms the backbone of spatial analysis in ice hockey, facilitating advanced strategy development and performance assessment.

% By integrating field point detection with YOLO and employing sophisticated techniques for homography computation, we can achieve precise mapping of player positions and field features onto a 2D rink representation, facilitating advanced spatial analyses for ice hockey analytics.

% \subsubsection{Conclusion}
% The integration of YOLO with field point detection, combined with sophisticated homography estimation techniques, offers a comprehensive framework for advanced sports analytics in ice hockey. This approach enhances the precision of player and feature tracking, enabling deeper analytical insights.

\end{spacing}
}




% {
% \setlength{\parskip}{0.3cm}
% \subsection{Heatmap Generation for Strategic Analysis}
% \begin{spacing}{1.2}

% Heatmaps are powerful tools for visualizing the frequency or intensity of player positions and movements across the rink, offering insights into team strategies, player behaviors, and game dynamics. This section will cover the technical details, algorithms, and relevant formulas used in the process, supported by suitable background material and references


% \end{spacing}
% }

% ########################## Methodology and Implementation ###############################

\section{Methodology and Implementation}

{
\setlength{\parskip}{0.3cm}
\subsection{Overview}
\begin{spacing}{1.2}

The following sections delineate the comprehensive plan and methodologies employed to construct a sophisticated system for tracking ice hockey players and referees in professional matches. This plan is meticulously designed to address the challenges unique to ice hockey tracking, leveraging advanced machine learning and computer vision techniques

\begin{enumerate}
    \item \textbf{Data Collection and Preprocessing} - gathering and preparing the necessary video data for analysis. It splits into two subsections, focusing on the extraction and annotation of player and referee data, and the calibration of ice hockey field points for spatial analysis. This step ensures the data quality and relevance for training the detection models and establishing a basis for accurate spatial tracking
    \item \textbf{Player and Referee Detection} - deployment of YOLO (You Only Look Once) for object detection, crucial for identifying players and referees within the video frames. The methodology behind training the model on the preprocessed dataset is elaborated, highlighting how the model learns to differentiate between players, referees, and other entities.
    \item \textbf{Team Classification}- after detection, the focus shifts to classifying players into their respective teams using clustering algorithms. Utilising feature extraction from player jerseys and the application of KMeans clustering for team classification based on color and pattern recognition
    \item \textbf{Player and Referee Tracking }- incorporating the DeepSORT algorithm to track the movement of each detected player and referee across frames, ensuring continuity and accuracy in player identification throughout the game.
    \item \textbf{Field Mapping and Point Generation} - converting the player positions from video coordinates to a 2D representation of the ice hockey field. Utilising mathematical models and algorithms used to achieve spatial consistency and accuracy
    \item \textbf{Heatmap} - the culmination of the tracking and classification efforts are used to generate heatmaps. These heatmaps visually represent player movements and concentrations on the field, providing valuable insights into team strategies and player performance.
    
\end{enumerate}

\end{spacing}
}


{
\setlength{\parskip}{0.3cm}
\subsection{Technical Framework}
\begin{spacing}{1.2}

The technical backbone of the project for tracking ice hockey players and referees in professional matches is built upon a selection of tools and technologies chosen for their proven capabilities in handling high-complexity tasks in image processing, machine learning, and data analysis. This section outlines the rationale behind the chosen technical framework, highlighting how each component contributes to achieving the project's objectives.

\begin{itemize}
    \item \textbf{Programming Language - Python}: Python was chosen as the primary programming language due to its extensive support for data manipulation, machine learning, and computer vision libraries. Its readability and concise syntax allow for rapid development and prototyping, which is essential in a research-oriented project like this. Furthermore, Python's widespread adoption in the scientific computing community ensures a wealth of resources and libraries, facilitating access to cutting-edge algorithms and tools.
    
    \item \textbf{Computer Vision - OpenCV}: OpenCV stands as a cornerstone for the project's computer vision needs, providing a comprehensive suite of functions for image and video analysis. Its robustness and efficiency in performing tasks such as image transformations, object detection, and feature extraction are critical for processing the high-frame-rate videos typical in ice hockey matches. The decision to utilize OpenCV is also motivated by its seamless integration with Python, allowing for a streamlined workflow from image preprocessing to object detection.
    
    \item \textbf{Machine Learning and Deep Learning - PyTorch}: PyTorch is selected for its dynamic computation graph and exceptional support for deep learning models, particularly beneficial for implementing and training the YOLO object detection model. Its intuitive design and flexibility enable quick experimentation with neural network architectures, while its efficient memory usage and GPU acceleration capabilities ensure fast model training and inference. PyTorch's extensive ecosystem and community support further provide access to pre-trained models and libraries, accelerating the development process.
    
    \item \textbf{Object Detection Model - YOLO (You Only Look Once)}: The YOLO model is specifically chosen for its ability to achieve real-time object detection, a critical requirement for tracking players and referees in live or recorded video streams. YOLO's unique architecture allows it to predict multiple bounding boxes and class probabilities for those boxes simultaneously, making it exceptionally efficient and suitable for applications requiring fast processing times. This efficiency does not come at the cost of accuracy, as YOLO demonstrates high precision in detecting and distinguishing between different objects within a frame.
    
    \item \textbf{Tracking Algorithm - DeepSORT}: DeepSORT is integrated into the project to handle the tracking aspect, building upon the detections provided by YOLO. It was selected for its robustness in tracking objects across frames, even in scenarios where detections might be missed or occluded temporarily. DeepSORT's utilization of deep learning features for association metrics significantly improves the tracking consistency and accuracy, making it ideal for following the fast and erratic movements of players and referees throughout a game.
\end{itemize}

The combination of these technologies forms a powerful technical framework capable of addressing the project's challenges. Each component was chosen not only for its individual strengths but also for how it complements the others, ensuring a cohesive and efficient system for tracking ice hockey players and referees. This technical foundation is crucial for achieving the project's goal of providing accurate, real-time analytics that can enhance team strategies and fan engagement.

\end{spacing}
}


{
\setlength{\parskip}{0.3cm}
\subsection{Data Collection and Preprocessing}
\begin{spacing}{1.2}

\subsubsection{Player and Referee Data}

\subsubsection{Ice Hockey Field Point Data}

\end{spacing}
}

{
\setlength{\parskip}{0.3cm}
\subsection{Player and Referee Detection}
\begin{spacing}{1.2}

\end{spacing}
}

{
\setlength{\parskip}{0.3cm}
\subsection{Team Classification}
\begin{spacing}{1.2}

\end{spacing}
}

{
\setlength{\parskip}{0.3cm}
\subsection{Player and Referee Tracking}
\begin{spacing}{1.2}

\end{spacing}
}

{
\setlength{\parskip}{0.3cm}
\subsection{Field Mapping and Point Generation}
\begin{spacing}{1.2}

\subsubsection{\textbf{CHANGE}: Point Generatoin}

\subsubsection{\textbf{CHANGE}: Point Detection}

\end{spacing}
}


{
\setlength{\parskip}{0.3cm}
\subsection{Heatmap}
\begin{spacing}{1.2}

\end{spacing}
}


\newpage


% ##################################### Evaluation #######################################

\section{Evaluation}

\subsection{Data Preperation}
\subsection{Player and Referee Detection}
\subsubsection{\textbf{CHANGE}: Hyperparameter Tuning}
\subsubsection{\textbf{CHANGE}: \textbf{CHANGE}: Optimisation of Detection Parameters}
\subsection{\textbf{CHANGE}: Field Point Detection}
\subsubsection{\textbf{CHANGE}: Hyperparameter Tuning}
\subsubsection{\textbf{CHANGE}: Optimisation of Detection Parameters}
\subsection{Player and Referee Tracking}
\subsection{Team Classification}
\newpage


% ############################## Conclusion and Reflections ################################

\section{Conclusion and Reflections}

\subsection{Achievements}
\subsection{Self Reflection}
\subsection{Future Work}
\subsubsection{1}
\subsubsection{2}
\subsubsection{3}
\subsection{Conclusion}
\newpage


\addcontentsline{toc}{section}{References}

\end{document}
